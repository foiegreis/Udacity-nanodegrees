{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"README.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMRYhS9UZ3+kwKaBABIvPLN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Object Detection in an Urban Environment\n","\n","\n","\n","##1. Exploratory data analysis\n","\n","In the 'Exploratory Data Analysis.ipynb' notebook you'll find the EDA performed on the dataset.\n","As a recall, these were some of the statistics covered:\n","\n","##Classes distribution\n","\n","![](https://drive.google.com/uc?id=1FuNF-gCKP7E4a9dvThZXG9DVGkW71fBE)\n","\n","##Brightness analysis\n","\n","![](https://drive.google.com/uc?id=1OXGlRqdP-mQPe005w4IJE9g0fdykIt_2)\n","\n","##BBoxes areas and centers-wise analysis\n","\n","![](https://drive.google.com/uc?id=1LZikM_lWkDOI7hxAv_UVxiwDYOy9wydn)\n","\n","\n","![](https://drive.google.com/uc?id=1yruuU7_CoZcetcMq-aqfurokhrmLcHvD)\n","\n","**Please see the notebook for further information**\n","\n","\n","##2. Data augmentation\n","\n","In the 'Data Augmentation.ipynb' notebook you'll find the EDA performed on the dataset.\n","As a recall, these were some of the techniques covered:\n","\n","\n","![](https://drive.google.com/uc?id=1_IwYOwrjrPc7ZIMRdaTBs13WioxSyx9r)\n","\n","![](https://drive.google.com/uc?id=1RZsGNZu9uSlLVvttAacXsZYTGhOLVhXJ)\n","\n","**Please see the notebook for further information**\n","\n","##3. Training\n","\n","##Reference experiment\n","\n","The Reference experiment refers to the training and evaluation of a ssdResnet50_v1 model, using transfer learning over the checkpoints downloaded from the modelzoo, on our custom dataset\n","\n","In the 'train_reference.ipynb' notebook you'll find all the steps and settings used to train the model.\n","\n","Here a snippet of the results\n","\n","![](https://drive.google.com/uc?id=1X8CvEeQkazFfWxucWQiqmQ1jOQ7c0Mhe)\n","\n","![](https://drive.google.com/uc?id=1W6sNtM-YIn1jOXyaYzx8pnfn3uN_V61b)\n","\n","![](https://drive.google.com/uc?id=18cNSbDgUh6cAaxuAOgrZVd2yXH1QUDvy)\n","\n","\n","##Analysis \n","In previous tries we noticed that the model couldn't converge even on the Train set. \n","In order to fix it, we lowered the optimizer momentum to 0.6.\n","\n","The results were clearly overfitting on the trainset. But this was a good baseline to check our model for further improvements (e.g. data augmentation, more training steps, learning rate tuning)\n","\n","##4. Improve on the reference\n","\n","##Experiment1 - **our best output**\n","\n","Above all the experiments we made, this was our best output.\n","Train and evaluate reference network with data Augmentation: ssd resnet50, batch 4, momentum 0.8, data augmentation, 25000 runs, lr 0.004\n","\n","Let's add data augmentation and train a bit longer. \n","Also, momentum 0.8 to prevent overfitting and data augmentation in the pipeline_new.config.\n","\n","## Analysis:\n","\n","Training longer and working on the data augmentation and learning rate improved a lot the process.\n","\n","(The loss visualization in tensorboard is not that accurate because many checkpoints were deleted based on the keep_max_num parameter in the trainer.py module of the od api. \n","We've also modified the model_lib_v2.py file in order to being able to visualize both the train and val data in tensorboard. Please have a look at the files for further information.)\n","\n","We can infer that the training loss is converging and the test loss is moving in the direction of the train, meaning the model isn't overfitting. Training for more epochs will lead to even better results.\n","\n","The mAp and recall were increasing, denoting the model was improving during the training. Of course, we could have reached better results training longer.\n","\n","![](https://drive.google.com/uc?id=1ZWEX6C8-9NtmEvsco7kkgYJNrqwHnWI1)\n","\n","![](https://drive.google.com/uc?id=1LNdlcaU1zm902kKU3otfkuzYu-cdHe29)\n","\n","![](https://drive.google.com/uc?id=1lE_tT8PZdLt888tKX3xDkeALwRfqQ5L1)\n","\n","\n","As you would see in the animation.mp4 file at this link, this was our best result\n","\n","https://drive.google.com/file/d/1oAYSkN6cecO78yMi_5IbhWXeYVhj7v2z/view?usp=sharing\n","\n","![](https://drive.google.com/uc?id=1z-Sr4fPIFah-Ze9xC1s0pv3UMLuCBKzi)\n","\n","Here the link to the exported model\n","\n","https://drive.google.com/drive/folders/1njrHlclFGYtLa-mRV2otzZoy6KqV81sS?usp=sharing\n","\n","\n","##Experiment 2 - great training curves but bad performances for box anchors\n","\n","Train and evaluate reference network with data Augmentation: ssd resnet50, batch 4, momentum 0.9, data augmentation, 30000 runs, lr 0.079 with decay,\n","changes from the original model in:\n","- batch non max suppression\n","- convolutional box predictor\n","- dropout\n","\n","Here a snippet of the results\n","\n","![](https://drive.google.com/uc?id=1hqkG-tDxHuqLZ3GP8SeetRb09OVKrPQI)\n","![](https://drive.google.com/uc?id=10GruBcPZoX2TWDpfGkiKx_4lubJJMkQK)\n","\n","##Analysis:\n","\n","Our chances on batch_non_max_suppression and convolutional_box_predictor performed poorly on our dataset, even if we tried to tailor the hyperparameters in order to take under consideration the infos we got from the eda process.\n","However, given the loss curves for train and eval, the dropout stage was performing well and we should keep it in future models.\n","\n","Here's the animation - look how the boxes do not cover the entire vehicle area!\n","https://drive.google.com/file/d/1eBdaPGyxyVahNsSDSSpNjYq7TN7Ltd8f/view?usp=sharing\n","\n","![](https://drive.google.com/uc?id=12eqjGcVPHpJiTtlRQ1Gh1FOADevEuoHN)\n","\n","link to the saved model\n","\n","https://drive.google.com/drive/folders/1d8hCchhA7cnEkycW1Oy4QnhIu-j8Dg_6?usp=sharing\n","\n","\n","\n","\n","\n"],"metadata":{"id":"xzMdPwOc0Pfz"}},{"cell_type":"code","source":[""],"metadata":{"id":"khQljIOt96TE"},"execution_count":null,"outputs":[]}]}